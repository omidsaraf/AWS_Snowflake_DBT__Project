# ====================================
# Core Python Packages
# ====================================
python-dotenv==1.0.1
pyyaml==6.0.1

# ====================================
# Apache Airflow
# ====================================
apache-airflow==2.8.1
apache-airflow-providers-amazon[s3]==8.15.0
apache-airflow-providers-snowflake==5.3.0
apache-airflow-providers-apache-spark==4.6.0

# ====================================
# dbt
# ====================================
dbt-core==1.7.4
dbt-snowflake==1.7.1
astronomer-cosmos[dbt-snowflake]==1.3.0

# ====================================
# AWS SDK
# ====================================
boto3==1.34.22
botocore==1.34.22
s3fs==2024.2.0
awscli==1.32.22

# ====================================
# Snowflake
# ====================================
snowflake-connector-python[pandas]==3.6.0
snowflake-sqlalchemy==1.5.1

# ====================================
# Apache Spark
# ====================================
pyspark==3.5.0

# ====================================
# Data Processing
# ====================================
pandas==2.1.4
pyarrow==14.0.2
fastparquet==2023.10.1
numpy==1.26.3

# ====================================
# Testing & Quality
# ====================================
pytest==7.4.4
pytest-cov==4.1.0
great-expectations==0.18.8
sqlfluff==3.0.0

# ====================================
# Utilities
# ====================================
requests==2.31.0
python-dateutil==2.8.2

##Airflow versions match the DAG examples (2.8.0) for compatibility with KubernetesPodOperator.
##PySpark 3.5.1 for Bronze/Silver ETL jobs.
##dbt-snowflake 1.7.0 for Data Vault transformations.
##boto3 for AWS S3 access from Spark and Airflow containers.
##snowflake-connector-python for dbt and ETL integration.
##Utilities like pandas and loguru for ETL transformations and logging.
